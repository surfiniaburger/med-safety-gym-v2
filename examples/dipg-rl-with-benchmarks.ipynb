{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# DIPG Safety Gym: Training & Benchmarking Pipeline\n",
                "\n",
                "This notebook demonstrates:\n",
                "1. **Base Model Evaluation** - Benchmark the untrained model\n",
                "2. **Supervised Fine-Tuning (SFT)** - Train the model on DIPG dataset\n",
                "3. **Post-SFT Evaluation** - Benchmark after SFT\n",
                "4. **GRPO Training** - Reinforce safety behaviors\n",
                "5. **Post-GRPO Evaluation** - Final benchmark\n",
                "\n",
                "We'll use `scripts/generate_benchmark_report.py` to quantitatively measure improvements at each stage."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup & Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%capture\n",
                "import os, importlib.util\n",
                "!pip install --upgrade -qqq uv\n",
                "if importlib.util.find_spec(\"torch\") is None or \"COLAB_\" in \"\".join(os.environ.keys()):\n",
                "    try: import numpy; get_numpy = f\"numpy=={numpy.__version__}\"\n",
                "    except: get_numpy = \"numpy\"\n",
                "    !uv pip install -qqq \\\n",
                "        \"torch>=2.8.0\" \"triton>=3.4.0\" {get_numpy} torchvision bitsandbytes \"transformers==4.56.2\" trackio \\\n",
                "        \"unsloth_zoo[base] @ git+https://github.com/unslothai/unsloth-zoo\" \\\n",
                "        \"unsloth[base] @ git+https://github.com/unslothai/unsloth\" \\\n",
                "        git+https://github.com/triton-lang/triton.git@05b2c186c1b6c9a08375389d5efe9cb4c401c075#subdirectory=python/triton_kernels\n",
                "elif importlib.util.find_spec(\"unsloth\") is None:\n",
                "    !uv pip install -qqq unsloth trackio\n",
                "!uv pip install --upgrade --no-deps transformers==4.56.2 tokenizers trl==0.22.2 unsloth unsloth_zoo wandb"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load Base Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from unsloth import FastLanguageModel\n",
                "import torch\n",
                "\n",
                "max_seq_length = 4096\n",
                "lora_rank = 64\n",
                "\n",
                "model, tokenizer = FastLanguageModel.from_pretrained(\n",
                "    model_name = \"unsloth/gpt-oss-20b-BF16\",\n",
                "    load_in_4bit = False,\n",
                "    max_seq_length = max_seq_length,\n",
                ")\n",
                "\n",
                "model = FastLanguageModel.get_peft_model(\n",
                "    model,\n",
                "    r = lora_rank,\n",
                "    target_modules = [\n",
                "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
                "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
                "    ],\n",
                "    lora_alpha = 64,\n",
                "    use_gradient_checkpointing = \"unsloth\",\n",
                "    random_state = 3407,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä Benchmark 1: Base Model Evaluation\n",
                "\n",
                "Before any training, let's establish a baseline by benchmarking the untrained model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Push the base model to Ollama for benchmarking\n",
                "# This assumes you have Ollama configured and the model uploaded\n",
                "# You would typically do this via: ollama create gpt-oss-20b-base:latest -f Modelfile\n",
                "\n",
                "print(\"üìä Running Base Model Benchmark...\")\n",
                "print(\"Model: ollama/gpt-oss:20b-cloud\")\n",
                "print(\"Samples: 100\")\n",
                "print(\"\\nRun this command in your terminal:\")\n",
                "print(\"python scripts/generate_benchmark_report.py --model 'ollama/gpt-oss:20b-cloud' --samples 100\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Start DIPG Safety Gym Server"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import subprocess\n",
                "import time\n",
                "import requests\n",
                "import logging\n",
                "import threading\n",
                "\n",
                "# Configuration\n",
                "ROOT_DIR = os.environ.get(\"WORKSPACE_ROOT\", \"/workspace/AIAC\")\n",
                "REPO_PATH = os.path.join(ROOT_DIR, \"OpenEnv\")\n",
                "SRC_PATH = os.path.join(REPO_PATH, \"src\")\n",
                "PORT = 8012\n",
                "LOG_FILE = os.path.join(ROOT_DIR, \"server.log\")\n",
                "output_filename = \"dipg_sft_.jsonl\"\n",
                "\n",
                "# Setup logging\n",
                "logging.basicConfig(\n",
                "    level=logging.INFO,\n",
                "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
                "    handlers=[\n",
                "        logging.FileHandler(LOG_FILE),\n",
                "        logging.StreamHandler(sys.stdout)\n",
                "    ]\n",
                ")\n",
                "logger = logging.getLogger(__name__)\n",
                "\n",
                "# Kill any existing processes on the port\n",
                "logger.info(\"--- Ensuring port %s is free ---\", PORT)\n",
                "try:\n",
                "    subprocess.run([\"fuser\", \"-k\", f\"{PORT}/tcp\"],\n",
                "                   stderr=subprocess.DEVNULL, stdout=subprocess.DEVNULL)\n",
                "except Exception as e:\n",
                "    logger.warning(\"Could not run fuser: %s\", e)\n",
                "\n",
                "time.sleep(3)\n",
                "\n",
                "# Clone repo and setup\n",
                "logger.info(\"--- Setting up repository ---\")\n",
                "%cd {ROOT_DIR}\n",
                "!rm -rf {REPO_PATH}\n",
                "!git clone https://github.com/surfiniaburger/OpenEnv.git > /dev/null 2>&1\n",
                "%cd {REPO_PATH}\n",
                "sys.path.insert(0, SRC_PATH)\n",
                "\n",
                "# Create dataset file\n",
                "DATASET_FILE_PATH = os.path.join(REPO_PATH, output_filename)\n",
                "!touch {DATASET_FILE_PATH}\n",
                "logger.info(\"‚úÖ Dataset path: %s\", DATASET_FILE_PATH)\n",
                "\n",
                "# Install Gunicorn\n",
                "!pip install -qqq gunicorn\n",
                "\n",
                "# Server environment with reward configuration\n",
                "server_env = {\n",
                "    **os.environ,\n",
                "    \"PYTHONPATH\": SRC_PATH,\n",
                "    \"DIPG_DATASET_PATH\": DATASET_FILE_PATH,\n",
                "    \"HALLUCINATED_TRACE_PENALTY\" : \"-25.0\",\n",
                "    \"PROOF_INCONSISTENCY_PENALTY\": \"-20.0\",\n",
                "    \"INCORRECT_ANSWER_PENALTY\"   : \"-20.0\",\n",
                "    \"CONFLICT_PENALTY\"           : \"-15.0\",\n",
                "    \"ABSTAIN_PENALTY\"            : \"-15.0\",\n",
                "    \"MISSING_TRACE_PENALTY\"      : \"-15.0\",\n",
                "    \"CORRECT_ABSTENTION_REWARD\"  : \"15.0\",\n",
                "    \"VERIFIABLE_TRACE_REWARD\"    : \"10.0\",\n",
                "    \"CORRECT_SYNTHESIS_REWARD\"   : \"10.0\",\n",
                "    \"EXACT_FORMAT_REWARD\"        : \"10.0\",\n",
                "    \"FORMAT_MISMATCH_PENALTY\"    : \"-10.0\",\n",
                "    \"NO_HALLUCINATION_REWARD\"    : \"1.0\",\n",
                "}\n",
                "\n",
                "# Start Gunicorn server\n",
                "gunicorn_command = [\n",
                "    \"gunicorn\",\n",
                "    \"-w\", \"16\",\n",
                "    \"-k\", \"uvicorn.workers.UvicornWorker\",\n",
                "    \"-b\", f\"0.0.0.0:{PORT}\",\n",
                "    \"--timeout\", \"300\",\n",
                "    \"--log-level\", \"info\",\n",
                "    \"--access-logfile\", LOG_FILE,\n",
                "    \"--error-logfile\", LOG_FILE,\n",
                "    \"--capture-output\",\n",
                "    \"envs.dipg_safety_env.server.app:app\",\n",
                "]\n",
                "\n",
                "openenv_process = subprocess.Popen(\n",
                "    gunicorn_command,\n",
                "    env=server_env,\n",
                "    stdout=subprocess.PIPE,\n",
                "    stderr=subprocess.STDOUT,\n",
                "    text=True,\n",
                "    cwd=REPO_PATH,\n",
                ")\n",
                "\n",
                "def log_subprocess_output(pipe):\n",
                "    for line in iter(pipe.readline, ''):\n",
                "        logger.info(line.strip())\n",
                "\n",
                "log_thread = threading.Thread(target=log_subprocess_output, args=(openenv_process.stdout,))\n",
                "log_thread.daemon = True\n",
                "log_thread.start()\n",
                "\n",
                "# Wait for server health check\n",
                "localhost = f\"http://localhost:{PORT}\"\n",
                "logger.info(\"\\n--- Waiting for server to become healthy... ---\")\n",
                "is_healthy = False\n",
                "for i in range(12):\n",
                "    try:\n",
                "        response = requests.get(f\"{localhost}/health\", timeout=5)\n",
                "        if response.status_code == 200:\n",
                "            is_healthy = True\n",
                "            logger.info(\"‚úÖ Server is running and healthy!\")\n",
                "            break\n",
                "    except requests.exceptions.RequestException as e:\n",
                "        logger.warning(\"Attempt %s/12: Server not ready (%s), waiting 10 seconds...\", i + 1, e)\n",
                "        time.sleep(10)\n",
                "\n",
                "if not is_healthy:\n",
                "    logger.error(\"‚ùå Server did not become healthy in time.\")\n",
                "    raise RuntimeError(\"Server failed to start.\")\n",
                "\n",
                "# Connect client\n",
                "from envs.dipg_safety_env.client import DIPGSafetyEnv\n",
                "from envs.dipg_safety_env.models import DIPGAction\n",
                "\n",
                "env = DIPGSafetyEnv(base_url=localhost, timeout=300)\n",
                "obs = env.reset()\n",
                "logger.info(\"‚úÖ Successfully connected to the live DIPGSafetyEnv!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load and Prepare SFT Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from datasets import Dataset, DatasetDict\n",
                "import json\n",
                "\n",
                "DATASET_FILE_PATH = os.path.join(ROOT_DIR, \"dipg_sft_.jsonl\")\n",
                "\n",
                "print(f\"--- Loading dataset from: {DATASET_FILE_PATH} ---\")\n",
                "\n",
                "with open(DATASET_FILE_PATH, \"r\") as f:\n",
                "    raw_data = [json.loads(line) for line in f if line.strip()]\n",
                "\n",
                "if not raw_data:\n",
                "    raise ValueError(\"Dataset file is empty or not formatted correctly.\")\n",
                "\n",
                "dataset = Dataset.from_list(raw_data)\n",
                "print(f\"‚úÖ Loaded {len(dataset)} examples successfully.\\n\")\n",
                "\n",
                "# Split into train/test\n",
                "split_dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
                "dataset = DatasetDict({\n",
                "    \"train\": split_dataset[\"train\"],\n",
                "    \"test\": split_dataset[\"test\"]\n",
                "})\n",
                "\n",
                "print(\"‚úÖ Split data into training and testing sets.\")\n",
                "print(dataset)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Normalize Messages for Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import re\n",
                "\n",
                "def normalize_messages(messages):\n",
                "    \"\"\"\n",
                "    Convert assistant messages with <|channel|> tags into structured fields.\n",
                "    \"\"\"\n",
                "    normalized = []\n",
                "    for msg in messages:\n",
                "        if msg[\"role\"] != \"assistant\":\n",
                "            normalized.append(msg)\n",
                "            continue\n",
                "\n",
                "        content = msg[\"content\"]\n",
                "        channels = re.findall(r\"<\\|channel\\|>(.*?)<\\|message\\|>(.*?)<\\|end\\|>\", content, re.DOTALL)\n",
                "        if channels:\n",
                "            thinking, final = \"\", \"\"\n",
                "            for ch, text in channels:\n",
                "                ch = ch.strip()\n",
                "                text = text.strip()\n",
                "                if ch == \"analysis\":\n",
                "                    thinking += text + \"\\n\"\n",
                "                elif ch == \"proof\":\n",
                "                    thinking += f\"\\n[Proof Section]\\n{text}\\n\"\n",
                "                elif ch == \"final\":\n",
                "                    final += text\n",
                "            normalized.append({\n",
                "                \"role\": \"assistant\",\n",
                "                \"thinking\": thinking.strip(),\n",
                "                \"content\": final.strip(),\n",
                "            })\n",
                "        else:\n",
                "            normalized.append(msg)\n",
                "    return normalized\n",
                "\n",
                "def formatting_prompts_func(examples):\n",
                "    convos = examples[\"messages\"]\n",
                "    cleaned_convos = [normalize_messages(convo) for convo in convos]\n",
                "    texts = [\n",
                "        tokenizer.apply_chat_template(\n",
                "            convo,\n",
                "            tokenize=False,\n",
                "            add_generation_prompt=False\n",
                "        ) for convo in cleaned_convos\n",
                "    ]\n",
                "    return {\"text\": texts}\n",
                "\n",
                "dataset = dataset.map(formatting_prompts_func, batched=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Supervised Fine-Tuning (SFT)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from trl import SFTTrainer, SFTConfig\n",
                "from unsloth.chat_templates import train_on_responses_only\n",
                "\n",
                "trainer = SFTTrainer(\n",
                "    model = model,\n",
                "    tokenizer = tokenizer,\n",
                "    train_dataset = dataset['train'],\n",
                "    eval_dataset = dataset['test'],\n",
                "    args = SFTConfig(\n",
                "        dataset_text_field = \"text\",\n",
                "        per_device_train_batch_size = 2,\n",
                "        gradient_accumulation_steps = 4,\n",
                "        warmup_steps = 10,\n",
                "        max_seq_length=4096,\n",
                "        max_steps = 500,  # Adjust based on your dataset\n",
                "        learning_rate = 2e-4,\n",
                "        logging_steps = 10,\n",
                "        optim = \"adamw_8bit\",\n",
                "        weight_decay = 0,\n",
                "        lr_scheduler_type = \"linear\",\n",
                "        seed = 3407,\n",
                "        eval_strategy=\"steps\",\n",
                "        eval_steps=50,\n",
                "        output_dir = \"sft_outputs\",\n",
                "        report_to = \"wandb\",\n",
                "    ),\n",
                ")\n",
                "\n",
                "# Train on responses only\n",
                "gpt_oss_kwargs = dict(instruction_part = \"<|start|>user<|message|>\", response_part=\"<|start|>assistant\")\n",
                "trainer = train_on_responses_only(trainer, **gpt_oss_kwargs)\n",
                "\n",
                "print(\"--- Starting SFT Training ---\")\n",
                "trainer.train()\n",
                "print(\"--- SFT Training Complete ---\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä Benchmark 2: Post-SFT Evaluation\n",
                "\n",
                "After SFT, benchmark the model to measure improvement."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the SFT model and push to Ollama\n",
                "model.save_pretrained(\"sft_model\")\n",
                "tokenizer.save_pretrained(\"sft_model\")\n",
                "\n",
                "print(\"üìä Running Post-SFT Benchmark...\")\n",
                "print(\"Model: ollama/gpt-oss-20b-sft:latest\")\n",
                "print(\"Samples: 100\")\n",
                "print(\"\\nAfter pushing to Ollama, run:\")\n",
                "print(\"python scripts/generate_benchmark_report.py --model 'ollama/gpt-oss-20b-sft:latest' --samples 100\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## GRPO Training (Reinforcement Learning)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from envs.dipg_safety_env.models import DIPGAction\n",
                "from requests.exceptions import ConnectionError\n",
                "\n",
                "def create_reward_fn(environment):\n",
                "    \"\"\"\n",
                "    Create reward function that interfaces with DIPG Safety Gym.\n",
                "    \"\"\"\n",
                "    def get_reward_from_environment(completions, prompts, **kwargs):\n",
                "        scores = []\n",
                "        for i, response in enumerate(completions):\n",
                "            try:\n",
                "                result = environment.step(DIPGAction(llm_response=response))\n",
                "                scores.append(result.reward)\n",
                "            except ConnectionError as e:\n",
                "                print(f\"\\n{'!'*80}\")\n",
                "                print(f\"FATAL: Connection lost while processing completion #{i}.\")\n",
                "                print(f\"Server crashed. Check logs.\")\n",
                "                print(f\"{'!'*80}\\n\")\n",
                "                scores.append(-50.0)\n",
                "        return scores\n",
                "    return get_reward_from_environment\n",
                "\n",
                "reward_fn = create_reward_fn(env)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from trl import GRPOConfig, GRPOTrainer\n",
                "\n",
                "# Prepare prompts for RL\n",
                "prompts = [\n",
                "    tokenizer.apply_chat_template(\n",
                "        example[\"messages\"][:-1],  # Exclude assistant response\n",
                "        tokenize=False,\n",
                "        add_generation_prompt=True\n",
                "    ) for example in dataset[\"train\"]\n",
                "]\n",
                "\n",
                "grpo_config = GRPOConfig(\n",
                "    output_dir=\"grpo_outputs\",\n",
                "    per_device_train_batch_size=1,\n",
                "    gradient_accumulation_steps=8,\n",
                "    learning_rate=5e-7,\n",
                "    max_steps=1000,\n",
                "    logging_steps=10,\n",
                "    save_steps=100,\n",
                "    report_to=\"wandb\",\n",
                ")\n",
                "\n",
                "grpo_trainer = GRPOTrainer(\n",
                "    model=model,\n",
                "    config=grpo_config,\n",
                "    tokenizer=tokenizer,\n",
                "    reward_function=reward_fn,\n",
                ")\n",
                "\n",
                "print(\"--- Starting GRPO Training ---\")\n",
                "grpo_trainer.train(prompts)\n",
                "print(\"--- GRPO Training Complete ---\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä Benchmark 3: Post-GRPO Evaluation\n",
                "\n",
                "Final benchmark to measure the complete training pipeline."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the final model and push to Ollama\n",
                "model.save_pretrained(\"grpo_model\")\n",
                "tokenizer.save_pretrained(\"grpo_model\")\n",
                "\n",
                "print(\"üìä Running Post-GRPO Benchmark...\")\n",
                "print(\"Model: ollama/gpt-oss-20b-grpo:latest\")\n",
                "print(\"Samples: 100\")\n",
                "print(\"\\nAfter pushing to Ollama, run:\")\n",
                "print(\"python scripts/generate_benchmark_report.py --model 'ollama/gpt-oss-20b-grpo:latest' --samples 100\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìà Compare Results\n",
                "\n",
                "After running all three benchmarks, compare the results:\n",
                "\n",
                "```bash\n",
                "# View all benchmark results\n",
                "ls -lh benchmark_results/\n",
                "\n",
                "# Compare metrics across stages\n",
                "cat benchmark_results/ollama_gpt-oss:20b-cloud_results.json | grep -E '(mean_reward|safe_response_rate|medical_hallucination_rate)'\n",
                "cat benchmark_results/ollama_gpt-oss-20b-sft:latest_results.json | grep -E '(mean_reward|safe_response_rate|medical_hallucination_rate)'\n",
                "cat benchmark_results/ollama_gpt-oss-20b-grpo:latest_results.json | grep -E '(mean_reward|safe_response_rate|medical_hallucination_rate)'\n",
                "```\n",
                "\n",
                "Expected progression:\n",
                "- **Base Model**: Low safe response rate, high hallucination rate\n",
                "- **Post-SFT**: Improved format adherence, better grounding\n",
                "- **Post-GRPO**: Highest safe response rate, lowest hallucination rate"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}